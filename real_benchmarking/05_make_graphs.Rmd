---
title: "Cluster Accuracy"
author: "Will Townes"
date: "10/19/2018"
output: html_document
---

```{r}
library(tidyverse)
sp<-TRUE #save plots?
fp<-file.path
# bp<-"./real_benchmarking"
bp = "."
pth0<-fp(bp,"results/tables")
if(!dir.exists(pth0)){
  dir.create(pth0,recursive=TRUE)
}
pth<-fp(bp,"results/fig")
if(!dir.exists(pth)){
  dir.create(pth,recursive=TRUE)
}
ggs<-function(plt,w=6,h=4){
  if(sp){ ggsave(file=fp(pth,plt),width=w,height=h) }
}
list.files("results")

#cbbPalette <- c("#000000", "#56B4E9", "#009E73", "#E69F00", "#D55E00", "#0072B2", "#CC79A7", "#F0E442")
pd<-read.table(fp(bp,"results/cluster_accuracy_all.txt"),header=TRUE)
# pd <- read.table(fp("./results/cluster_accuracy.txt"), header=T)
pd$ktrue<-4
pd$ktrue[pd$dat=="Zhengmix8eq"]<-8
head(pd)
pd$dimreduce<-factor(pd$dimreduce,levels=c("glmpca","pca_rd","pca_rp","zinbwave","pca_log", "pca_log_frac"))

d0<-d<-subset(pd,method!="mclust" & k>=floor(.75*ktrue) & k<=ceiling(1.25*ktrue) & num_genes==1500 & genefilter!="expr")
d$genefilter<-plyr::mapvalues(d$genefilter,from=c("hvg","dev"),to=c("Highly variable","Deviance"))
d$dimreduce<-plyr::mapvalues(d$dimreduce,from=c("glmpca","pca_rd","pca_rp","zinbwave","pca_log","pca_log_frac"),to=c("GLM-PCA","Deviance residual PCA","Pearson residual PCA","ZINB-WAVE","Log-CPM PCA", "Log-Frac PCA"))
```

ari=adjusted rand index (high value= better concordance between learned clusters and ground truth cluster annotations)

Twelve tables: separate table for each dataset (3), number of dimensions (2), and kmeans/seurat (2). Each table is ranked by median performance. Columns: dimreduce, number of dims, filtering type incl expr, only seurat with correct clusters, 3 ARI (min,median,max). 8eq is primary table, 4eq and 4uneq is supplemental. Use colors in cells of the table.

```{r}
#m<-"seurat"; z<-"Zhengmix4eq"; L<-10
for(m in c("seurat","kmeans")){
  for(z in paste0("Zhengmix",c("4eq","4uneq","8eq"))){
    for(L in c(10,30)){
      d2<-subset(d,method==m & dat==z & dims==L)
      d3<-d2 %>% group_by(genefilter,dimreduce) %>% summarize(med_ari=median(ari),min_ari=min(ari),max_ari=max(ari)) %>% arrange(desc(med_ari))
      d3[,3:5]<-round(d3[,3:5],3)
      colnames(d3)<-c("Feature Selection","Dimension Reduction","Med. ARI","Min. ARI","Max. ARI")
      fname<-fp(pth0,paste0(z,"_",m,"_L",L,"_clustering_summary.csv"))
      write.csv(d3,file=fname,quote=FALSE,row.names=FALSE)
    }
  }
}
```

Figure 1- restrict attention to Seurat with roughly the correct number of clusters, where we start with 1500 genes and project onto 10 or 30 latent dimensions. Exclude Zheng4uneq because the results are very similar to Zheng4eq and it crowds the plot.

```{r}
pd1<-subset(pd,method=="seurat" & num_genes==1500 & k>=floor(.75*ktrue) & k<=ceiling(1.25*ktrue) & dat!="Zhengmix4uneq")
pd1$dims<-plyr::mapvalues(pd1$dims,from=c(10,30),to=c("10 dimensions","30 dimensions"))
pd1$genefilter<-plyr::mapvalues(pd1$genefilter,from=c("dev","expr","hvg"),to=c("Deviance","Highly expressed","Highly variable"))
#pd1$dimreduce<-factor(pd1$dimreduce,levels=c("glmpca","pca_rd","pca_rp","pca_log","zinbwave"))#,ordered=TRUE)
ggplot(pd1,aes(x=genefilter,y=ari,fill=dimreduce,colour=dimreduce))+geom_boxplot()+facet_grid(dims~dat)+theme_bw()+ylab("adjusted Rand Index")+xlab("feature selection")+theme(axis.text.x=element_text(angle=15,hjust=1))
ggs("seurat_G1500_all.pdf")
```

Seurat only, deviance only, datasets 4eq and 8eq, no highly expressed genes, no pearson residuals

```{r}
#note d0 already excludes highly expressed genes
d2<-subset(d, dat!="Zhengmix4uneq" & method=="seurat" & dimreduce!="Pearson residual PCA")
d2$dimreduce<-plyr::mapvalues(d2$dimreduce,from="Deviance residual PCA",to="Dev. resid. PCA")
d2$dims<-plyr::mapvalues(d2$dims,from=c(10,30),to=c("10 dimensions","30 dimensions"))
ggplot(subset(d2,genefilter=="Deviance"),aes(x=dimreduce,y=ari,fill=dimreduce,colour=dimreduce))+geom_boxplot()+theme_bw()+facet_grid(dims~dat)+theme(axis.text.x=element_text(angle=20,hjust=1),axis.title.x=element_blank(),legend.position = "none")+ylab("adjusted Rand index")
ggs("benchmark_dimreduce.pdf")
```

GLM-PCA and Log-CPM PCA showing Deviance vs HVG for Feature Selection

```{r}
d2b<-subset(d2,dims=="10 dimensions" & dimreduce %in% c("GLM-PCA","Log-CPM PCA", "Log-Frac PCA"))
d2b$genefilter<-factor(d2b$genefilter)
d2b$genefilter<-plyr::mapvalues(d2b$genefilter,from="Highly variable",to="Highly variable genes")
ggplot(d2b, aes(x=dimreduce,y=ari,fill=genefilter,colour=genefilter)) +geom_boxplot()+facet_wrap(~dat,scales="fixed",nrow=1) +theme_bw()+ylab("adjusted Rand index") +theme(legend.position="bottom", axis.title.x=element_blank())+labs(fill=NULL,color=NULL)#+labs(fill="feature selection",colour="feature selection")
ggs("benchmark_featselect.pdf",h=2.5)
```

Kmeans only, compare feat select Deviance vs HVG and dimreduce GLM-PCA vs Log-CPM PCA.

```{r}
d3<-subset(d, dat!="Zhengmix4uneq" & method=="kmeans" & dimreduce %in% c("Log-CPM PCA","GLM-PCA", "Log-Frac PCA"))
d3$dims<-plyr::mapvalues(d3$dims,from=c(10,30),to=c("10 dimensions","30 dimensions"))
#d3$gfdr<-NA
#d3$gfdr[d3$genefilter=="Deviance" & d3$dimreduce=="GLM-PCA"]<-"Dev. GLM-PCA"
#d3$gfdr[d3$dimreduce=="Log-CPM PCA" & d3$genefilter=="Highly variable"]<-"HVG log-CPM PCA"
#d3<-subset(d3,!is.na(gfdr))
colnames(d3)[colnames(d3)=="method"]<-"clustering"
#colnames(d3)[colnames(d3)=="gfdr"]<-"method"
ggplot(d3,aes(x=genefilter,y=ari,fill=dimreduce,colour=dimreduce))+geom_boxplot()+facet_grid(dims~dat)+theme_bw()+ylab("adjusted Rand index")+xlab("feature selection")
#ggplot(d3,aes(x=method,y=ari,fill=method,colour=method))+geom_boxplot()+facet_grid(dims~dat)+theme_bw()+ylab("adjusted Rand index")
ggs("benchmark_kmeans.pdf")
```

### Old Stuff

```{r}
dats<-unique(pd$dat)
#how sensitive are results to number of clusters (k)
for(j in 1:length(dats)){
  show(ggplot(subset(pd,dat==dats[j]),aes(x=k,y=ari,colour=dimreduce))+geom_point()+facet_grid(dims~method,scales="free_x")+ggtitle(dats[j]))
}

#how sensitive are results to number of variable genes (G)?
for(j in 1:length(dats)){
  z<-subset(pd,dat==dats[j] & k==ktrue)
  show(ggplot(z,aes(x=factor(num_genes),y=ari,colour=dimreduce))+geom_point()+facet_grid(dims~method)+ggtitle(dats[j]))
}

#assuming we choose the right number of clusters,
#what is the best gene filtering and dimension reduction strategy?
#for(j in 1:length(dats)){
  j<-3
  z<-subset(pd,dat==dats[j] & k>=floor(.75*ktrue) & k<=ceiling(1.25*ktrue))
  show(ggplot(z,aes(x=genefilter,y=ari,fill=dimreduce,colour=dimreduce))+geom_boxplot()+facet_grid(dims~method)+theme_bw())#+ggtitle(dats[j]))
  ggs("zheng8eq_all.pdf")
#}
```

Try to quantify differences between methods using a linear regression model

```{r}
pd2<-subset(pd,k<=12)
pd2$method<-relevel(pd2$method,"seurat")
pd2$dimreduce<-relevel(pd2$dimreduce,"glmpca")
pd2$num_genes_cat<-factor(pd2$num_genes)
pd2$num_genes_cat<-relevel(pd2$num_genes_cat,"300")

for(j in dats){
  print(paste("***********",j,"***********"))
  fit<-lm(ari~num_genes_cat+factor(dims)+method+genefilter+dimreduce+poly(k-ktrue,2),data=subset(pd2,dat==j))
  print(summary(fit))
}
```

Conclusions

* **Gene filtering method**- Binomial deviance was significantly better than "highly expressed genes" and "highly variable genes" in all datasets.
* **Number of variable genes**- increasing number of variable genes improves clustering performance, but the rate of improvement tapers off beyond a few hundred genes. 
* **Dimension Reduction**- On the 4eq and 4uneq datasets, PCA on Binomial deviance or Pearson residuals was the best method, followed by GLM-PCA. ZINB-WAVE and PCA on log CPM performed worse than GLM-PCA. For ZINB-WAVE, this was largely due to its degradation in performance when the latent dimension was increased from 10 to 30. On the more difficult 8eq dataset, GLM-PCA significantly outperformed all other methods, with deviance residuals as the second best.
* **Number of latent dimensions**- changing number of dimensions from 10 to 30 worsened performance, although this was probably driven more by ZINB-WAVE than other dimension reductions. GLM-PCA and PCA on deviance or Pearson residuals were robust to the number of latent dimensions.
* **Clustering Algorithm**- Seurat significantly better than both kmeans and mclust on all datasets.
* **Number of clusters**- strong effect of choosing right number of clusters.
